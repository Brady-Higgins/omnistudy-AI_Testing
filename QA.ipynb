{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf21372e-5ae9-4147-9e4c-0d63cbb53dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brady\\.vscode\\omnistudy-AI_Testing\\venv\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "#overide = true just forces a reload on the .env file in case api key changes\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Access the API key\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "huggingface_api_token = os.getenv(\"HUGGING_FACE_API_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5083a36-6d22-4172-9e73-3aa00daaeddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Brady\\.vscode\\omnistudy-AI_Testing\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize the pinecone index\n",
    "import pinecone      \n",
    "\n",
    "pinecone.init(      \n",
    "\tapi_key=pinecone_api_key,      \n",
    "\tenvironment='gcp-starter'      \n",
    ")      \n",
    "index = pinecone.Index('haystack')\n",
    "\n",
    "#load a pinecone document store object with the index defined previously\n",
    "from haystack.document_stores import PineconeDocumentStore\n",
    "\n",
    "document_store = PineconeDocumentStore(\n",
    "    api_key=pinecone_api_key,\n",
    "    pinecone_index=index,\n",
    "    similarity=\"cosine\",\n",
    "    embedding_dim=768\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348ebde1-21da-479b-8dd9-82924eb5db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brady\\.vscode\\omnistudy-AI_Testing\\venv\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "#Initialize retriever model\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"flax-sentence-embeddings/all_datasets_v3_mpnet-base\",\n",
    "    model_format=\"sentence_transformers\"\n",
    ")\n",
    "from haystack.pipelines import DocumentSearchPipeline\n",
    "\n",
    "search_pipe = DocumentSearchPipeline(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25476a91-4f84-4576-b26b-4543d201d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do you prepare for a coding interview?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f9a604-9d3d-4438-94ed-a4d22120aeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfce8aefb542413fb3ba77f750ca4d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs = search_pipe.run(query=query, params={\"Retriever\": {\"top_k\": 2}})['documents']\n",
    "documents = []\n",
    "for doc in docs:\n",
    "    documents.append(doc.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120353d4-b737-43d8-b10e-4ffcfc541795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supporting documents provided \n",
      "\n",
      "Hints are provided at the back of this book, but push yourself to\n",
      "develop a solution with as little help as possible. Many questions are designed to be tough-that's okay!\n",
      "When you're solving a problem, make sure to think about the space and time efficiency.\n",
      "2.\n",
      "Write the code on paper. Coding on a computer offers luxuries such as syntax highlighting, code comple­\n",
      "tion, and quick debugging. Coding on paper does not. Get used to this-and to how slow it is to write\n",
      "and edit code-by coding on paper.\n",
      "3. Test your code-on paper. This means testing the general cases, base cases, error cases, and so on. You'll\n",
      "need to do this during your interview, so it's best to practice this in advance.\n",
      "4. Type your paper code as-is into a computer. You will probably make a bunch of mistakes. Start a list of all\n",
      "the errors you make so that you can keep these in mind during the actual interview.\n",
      "In addition, try to do as many mock interviews as possible. You and a friend can take turns giving each other\n",
      "mock interviews. Though your friend may not be an expert interviewer, he or she may still be able to walk\n",
      "you through a coding or algorithm problem. You'll also learn a lot by experiencing what it's like to be an\n",
      "interviewer.\n",
      "\u0014 What You Need To Know\n",
      "The sorts of data structure and algorithm questions that many companies focus on are not knowledge\n",
      "tests. \n",
      "Try to add on\n",
      "one more project .\n",
      "•\n",
      "Create draft of resume\n",
      "...__\n",
      "and send it out for a\n",
      "resume review .\n",
      "_____.\n",
      "tures and algorithms\n",
      "_____.\n",
      "Form mock interview\n",
      "group with friends to\n",
      "interview each other .\n",
      "from scratch.\n",
      "Do mini-projects to\n",
      "...__\n",
      "solidify understanding\n",
      "of ke conce ts .\n",
      "Create list to track\n",
      "-----.\n",
      "mistakes you've made\n",
      "-----.\n",
      "solving problems.\n",
      "Review/ update\n",
      "resume.\n",
      "•\n",
      "•\n",
      "Create interview prep\n",
      "grid (pg 32).\n",
      "t\n",
      "Cracking the Coding Interview, 6th Edition\f",
      "Re-read intro to CtCi,\n",
      "especially Tech &\n",
      "__..\n",
      "Behavioral section.\n",
      "Do a final mock\n",
      "interview.\n",
      "•\n",
      "Rehearse stories\n",
      "from the interview\n",
      "__..\n",
      "prep grid (pg 32).\n",
      "Rehearse each story\n",
      "from interview prep\n",
      ".._\n",
      "grid once .\n",
      "•\n",
      "Continue to practice\n",
      "questions & review\n",
      "__..\n",
      "your list of mistakes.\n",
      "Remember to talk out\n",
      "loud. Show how you\n",
      ".._\n",
      "think .\n",
      "•\n",
      "Don't forget: Stum-\n",
      "bling and struggling is __..\n",
      "normal!\n",
      "Get an offer? Celebrate!\n",
      "Your hard work paid\n",
      "..__\n",
      "off!\n",
      "IV I Before the Interview\n",
      "Do another mock\n",
      "Continue to practice\n",
      "__..\n",
      "questions, writing\n",
      "interview.\n",
      "code on paper.\n",
      "•\n",
      "Phone Interview:\n",
      "Locate headset and/or\n",
      "video camera .\n",
      "Re-read Algorithm\n",
      "__..\n",
      "Re-read Big O section\n",
      "Approaches (pg 67).\n",
      "(pg 38).\n",
      "•\n",
      ".._\n",
      "Continue to practice\n",
      "interview questions.\n",
      "Review Powers of 2\n",
      "table (pg 61 ). Print\n",
      "__..\n",
      "for a phone screen.\n",
      "•\n",
      "Be Confident (Not\n",
      "Wake up in plenty of\n",
      ".._\n",
      "time to eat a good\n",
      "Cocky!).\n",
      "breakfast & be on time.\n",
      "__..\n",
      "Write Thank You note\n",
      "to recruiter.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"supporting documents provided \\n\")\n",
    "for text in documents:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8197d219-0f8b-4726-84ad-b34e5fe55028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"vblagoje/bart_lfqa\"\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "# model = model.to(device)\n",
    "\n",
    "\n",
    "conditioned_doc = \"<P> \" + \" <P> \".join([d for d in documents])\n",
    "query_and_docs = \"question: {} context: {}\".format(query, conditioned_doc)\n",
    "\n",
    "model_input = tokenizer(query_and_docs, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "generated_answers_encoded = model.generate(input_ids=model_input[\"input_ids\"],\n",
    "                                           attention_mask=model_input[\"attention_mask\"],\n",
    "                                           min_length=64,\n",
    "                                           max_length=256,\n",
    "                                           do_sample=False, \n",
    "                                           early_stopping=True,\n",
    "                                           num_beams=8,\n",
    "                                           temperature=1.0,\n",
    "                                           eos_token_id=tokenizer.eos_token_id,\n",
    "                                           no_repeat_ngram_size=3,\n",
    "                                           num_return_sequences=1)\n",
    "answer = tokenizer.batch_decode(generated_answers_encoded, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43951ef7-7f40-4969-a4e8-1a2b5153a88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm not sure if this is what you're looking for, but I'll give it a shot. First of all, you need to know what a coding interview is. It's not a job interview, it's an interview to see if you can be a good programmer. If you don't know how to code, you're not going to be able to do it well enough to get a good job. Second, you have to understand what the interviewer is looking for. They want you to be a programmer, but they don't want to hire someone who doesn't know what they're talking about. So, they ask you a bunch of questions, and you try to answer them as best as you can. You'll probably make a lot of mistakes during the interview, but you'll also learn a lot.\"]\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7bc869-210a-4e74-ae17-01a094231f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
